{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e0996c-7aeb-4edc-8572-cf65488c1dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nInputs = paramRVEdataset.hd5, snapshots.hd5 (described before) \\nOutputs: \\n- Wbasis.hd5: Reduced-Basis matrices and singular values. Same comment for labels 'A' and 'S' (above) applies.  \\n- XY.hd5: Assemble important data of paramRVEdataset.hd5 (to be used as the input of NN training) and also the projected solutions of the snapshots (snapshots.hd5) onto the RB (Wbasis.hd5). Same comment for labels 'A' and 'S' (above) applies.\\n\\nObs: Wbasis.hd5 should be obtained to the larger dataset (usually the training one), then should be reused to obtain XY.hd5 files of the remaining datasets. \\n\\nThe typical order of execution is with op= 0, 1, 2, 3 (one after another). Op = 1 (RB basis obtention) can be skipped according to the situation. \\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inputs = paramRVEdataset.hd5, snapshots.hd5 (described before) \n",
    "Outputs: \n",
    "- Wbasis.hd5: Reduced-Basis matrices and singular values. Same comment for labels 'A' and 'S' (above) applies.  \n",
    "- XY.hd5: Assemble important data of paramRVEdataset.hd5 (to be used as the input of NN training) and also the projected solutions of the snapshots (snapshots.hd5) onto the RB (Wbasis.hd5). Same comment for labels 'A' and 'S' (above) applies.\n",
    "\n",
    "Obs: Wbasis.hd5 should be obtained to the larger dataset (usually the training one), then should be reused to obtain XY.hd5 files of the remaining datasets. \n",
    "\n",
    "The typical order of execution is with op= 0, 1, 2, 3 (one after another). Op = 1 (RB basis obtention) can be skipped according to the situation. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1224d55-ff51-4b42-9025-0ad477a7b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "from dolfin import *\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepBND.__init__ import *\n",
    "import deepBND.creation_model.RB.RB_utils as rbut\n",
    "import deepBND.core.multiscale.misc as mtsm\n",
    "\n",
    "from fetricks.fenics.mesh.mesh import Mesh \n",
    "import fetricks.data_manipulation.wrapper_h5py as myhd\n",
    "\n",
    "dotProduct = lambda u,v, dx_ref: inner(u,v)*dx_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7285392b-9bc5-4f5c-b1e5-68f1b5f70178",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = rootDataPath + \"/review2_smaller/dataset/\"\n",
    "folder_mesh = rootDataPath + \"/review2_smaller/dataset/\"\n",
    "\n",
    "suffix = ''\n",
    "nameSnaps = folder + 'snapshots%s.hd5'%suffix\n",
    "nameMeshRefBnd = folder_mesh + 'boundaryMesh.xdmf'\n",
    "nameWbasis = folder + 'Wbasis.hd5'\n",
    "nameYlist = folder + 'Y%s.hd5'%suffix\n",
    "nameXYlist = folder + 'XY%s.hd5'%suffix\n",
    "nameParamRVEdataset = folder + 'paramRVEdataset%s.hd5'%suffix\n",
    "\n",
    "Mref = Mesh(nameMeshRefBnd)\n",
    "Vref = VectorFunctionSpace(Mref,\"CG\", 2)\n",
    "\n",
    "dxRef = Measure('dx', Mref) \n",
    "dsRef = Measure('ds', Mref) \n",
    "Nh = Vref.dim()\n",
    "print(Nh)\n",
    "\n",
    "Nmax = 2000\n",
    "\n",
    "op = 4\n",
    "\n",
    "# if(op==0):\n",
    "#    translateSolution(nameSnaps, Vref)\n",
    "#elif(op==1):\n",
    "#    computingBasis(nameSnaps, nameWbasis, Nmax, Nh, Vref, dsRef)\n",
    "#elif(op==2):\n",
    "#    extractAlpha(nameSnaps, nameWbasis, Nmax, nameYlist, Vref, dsRef)\n",
    "#elif(op==3):\n",
    "#    createXY(nameParamRVEdataset, nameYlist, nameXYlist, id_feature = [0,1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1258af6-7229-4095-84aa-17e73ed4e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def translateSolution(nameSnaps, Vref):\n",
    "for load_flag in ['A', 'S']:\n",
    "    labels = ['solutions_%s'%load_flag,'a_%s'%load_flag,'B_%s'%load_flag]\n",
    "    Isol, fIsol = myhd.loadhd5_openFile(nameSnaps,labels, mode = 'a')\n",
    "    Isol_full , Isol_a, Isol_B = Isol # a = -avg(disp), B = - avg(strain) \n",
    "    Isol_trans = Isol_full[:,:]\n",
    "    usol = Function(Vref)\n",
    "    ns = len(Isol_trans)\n",
    "    for i in range(ns):\n",
    "        print('translating ', i)\n",
    "        usol.vector().set_local(Isol_full[i,:])\n",
    "        Ttrans = mtsm.affineTransformationExpression(Isol_a[i,:], np.zeros((2,2)), Mref) # B = 0\n",
    "        Tfluc = mtsm.affineTransformationExpression(Isol_a[i,:], Isol_B[i,:,:], Mref) # B = 0\n",
    "        Isol_fluc[i,:] = Isol_fluc[i,:] + interpolate(Tfluc,Vref).vector().get_local()[:] \n",
    "        Isol_trans[i,:] = Isol_trans[i,:] + interpolate(Ttrans,Vref).vector().get_local()[:] \n",
    "\n",
    "    myhd.addDataset(fIsol,Isol_fluc, 'solutions_fluctuations_%s'%load_flag)\n",
    "    myhd.addDataset(fIsol,Isol_trans, 'solutions_translation_%s'%load_flag)\n",
    "    fIsol.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295441ee-13c9-41fb-8b3f-fdffdf39bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def computingBasis(nameSnaps, nameWbasis, Nmax, Nh, Vref, dsRef):\n",
    "os.system('rm ' + nameWbasis)\n",
    "Wbasis_fields, f = myhd.zeros_openFile(nameWbasis, [(Nmax,Nh),(Nmax,Nh),(Nmax,),(Nmax,),(Nh,Nh)], \n",
    "                                                   ['Wbasis_A', 'Wbasis_S','sig_A', 'sig_S','massMat'])\n",
    "Wbasis_A , Wbasis_S, sig_A, sig_S, Mmat = Wbasis_fields\n",
    "for load_flag, Wbasis, sig in zip(['A', 'S'],[Wbasis_A , Wbasis_S], [sig_A,sig_S]):\n",
    "    Isol = myhd.loadhd5(nameSnaps,'solutions_fluctuations_%s'%load_flag)\n",
    "    sig[:] = rbut.computingBasis_svd(Wbasis, Mmat, Isol,Nmax,Vref, dsRef, dotProduct)[0][:Nmax] # Mmat equal to both\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d24e5-c21d-440e-85d0-8c53e051a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extractAlpha(nameSnaps, nameWbasis, Nmax, nameYlist, Vref, dsRef):\n",
    "os.system('rm ' + nameYlist)\n",
    "for load_flag in ['A', 'S']:\n",
    "    Wbasis_M = myhd.loadhd5(nameWbasis, ['Wbasis_%s'%load_flag,'massMat'])\n",
    "    Isol = myhd.loadhd5(nameSnaps,'solutions_fluctuations_%s'%load_flag)\n",
    "    ns = len(Isol)\n",
    "    Ylist = rbut.getAlphas_fast(Wbasis_M,Isol, ns, Nmax, dotProduct, Vref, dsRef)\n",
    "    if os.path.exists(nameYlist):\n",
    "        fIsol = myhd.loadhd5_openFile(nameYlist, [], mode = 'a')[1]\n",
    "        myhd.addDataset(fIsol,Ylist,'Ylist_%s'%load_flag)\n",
    "        fIsol.close()\n",
    "    else:\n",
    "        myhd.savehd5(nameYlist,Ylist,'Ylist_%s'%load_flag, mode='w') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da994bf-c5ad-4eb4-968c-1868bf501df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createXY(nameParamRVEdataset, nameYlist, nameXYlist, id_feature = 2):\n",
    "os.system('rm ' + nameXYlist)\n",
    "Y = myhd.loadhd5(nameYlist,['Ylist_%s'%s for s in ['A','S']])\n",
    "X = myhd.loadhd5(nameParamRVEdataset,'param')[:,:, id_feature]\n",
    "X = X.reshape((X.shape[0],-1))\n",
    "myhd.savehd5(nameXYlist, Y + [X], ['Y_%s'%s for s in ['A','S']] + ['X'], mode='w')\n",
    "os.system('rm ' + nameYlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6814b1-ae10-4479-90e4-d13fbbb88d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting elif(op==4): # train,  validation, test splitting\n",
    "    ns = len(myhd.loadhd5(nameParamRVEdataset, \"id\"))\n",
    "    seed = 2\n",
    "    np.random.seed(seed)\n",
    "    shuffled_ids = np.arange(0,ns) \n",
    "    np.random.shuffle(shuffled_ids)\n",
    "\n",
    "    r_val = 0.05\n",
    "    r_test = 0.0001\n",
    "\n",
    "    id_val = np.arange(0, int(np.floor(r_val*ns))).astype('int')\n",
    "    id_test = np.arange(id_val[-1] + 1, int(np.floor((r_val+r_test)*ns)))\n",
    "    id_train = np.arange(id_test[-1], ns)\n",
    "\n",
    "    id_val = shuffled_ids[id_val]\n",
    "    id_test = shuffled_ids[id_test]\n",
    "    id_train = shuffled_ids[id_train]\n",
    "\n",
    "    labels = ['X', 'Y_A', 'Y_S']\n",
    "    X, Y_A, Y_S = myhd.loadhd5(nameXYlist, labels )  \n",
    "\n",
    "    myhd.savehd5(nameXYlist.split('.')[0] + \"_val.hd5\" , [X[id_val], Y_A[id_val], Y_S[id_val]], labels , \"w-\")\n",
    "    myhd.savehd5(nameXYlist.split('.')[0] + \"_test.hd5\", [X[id_test], Y_A[id_test], Y_S[id_test]], labels , \"w-\")\n",
    "    myhd.savehd5(nameXYlist.split('.')[0] + \"_train.hd5\", [X[id_train], Y_A[id_train], Y_S[id_train]], labels , \"w-\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_fenics",
   "language": "python",
   "name": "tf_fenics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
